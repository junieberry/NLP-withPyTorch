{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_SequenceModeling_forBeginner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPImZnudZoA679xyxgm8j2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/NLP-withPyTorch/blob/main/06_SequenceModeling_forBeginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QPT35c8LXQ3"
      },
      "source": [
        "자연어는 시계열 데이터이다!\n",
        "\n",
        "따라서 자연어 처리를 위해 시퀀스 모델링이 필요!\n",
        "\n",
        "시퀀스 모델링은 **은닉 상태**를 유지한다.\n",
        "\n",
        "은닉 상태는 지금까지의 시퀀스에 대한 정보를 **시퀀스 표현**에 담는다.\n",
        "\n",
        "시퀀스 모델로 시퀀스를 분류하거나, 생성할 수 있당\n",
        "\n",
        "이번에는 시퀀스 분류를 배워보자~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATBrR4CGZnOJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0POMqhLwUslP"
      },
      "source": [
        "## 6.1 순환 신경망 소개\n",
        "\n",
        "\n",
        "- t에서는 타임 스텝 t에서의 입력 벡터와 타임 스텝 t-1에서의 은닉 벡터를 사용한다.\n",
        "- 각각 은닉-은닉 가중치와 입력-은닉 가중치를 사용한다.\n",
        "- 이때 가중치는어느 시간에서나 같은 파라미터를 공유한다.\n",
        "\n",
        "- 시퀀스 모델은 가변 길이 시퀀스를 다룰 수 있어야 한다.\n",
        "  - 책에서는 마스킹을 사용한다.\n",
        "  - 마스킹을 통해 그레디언트나 최종 출력에 포함되어서는 안된다는 신호를 보낼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5aOS2WYBa-"
      },
      "source": [
        "### 6.1.1 엘만 RNN 구현하기\n",
        "\n",
        "파이토치 RNN 클래스가 엘만 RNN의 구현이다.\n",
        "\n",
        "하지만 여기서는 RNNCell을 사용해 RNN을 만든다!\n",
        "\n",
        "**RNNCell**\n",
        "- 입력-은닉 가중치와 은닉-은닉 가중치\n",
        "- RNNCell() 호출마다 입력 벡터 행렬과 은닉 벡터 행렬을 받는다.\n",
        "- 그리고 은닉 벡터를 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_CDJpW7IHfS"
      },
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "\n",
        "  ## input_size (int) == 입력 벡터 크기\n",
        "  ## hidden_size (int) == 은닉 벡터 크기\n",
        "  ## batch_first (boolean) == 0번째 차원이 배치인가?\n",
        "  def __init__(self, input_size, hidden_size, batch_first=False):\n",
        "    super(ElmanRNN, self).__init__()\n",
        "\n",
        "    ## RNNCell 사용\n",
        "    self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "    self.batch_first = batch_first\n",
        "    self.hidden_size = hidden_size\n",
        "  \n",
        "  def _initialize_hidden(self, batch_size):\n",
        "    return torch.zeros(batch_size, self.hidden_size)\n",
        "  \n",
        "\n",
        "  # ElmanRNN의 정방향 계산\n",
        "  ## x_int (tensor) == 입력 데이터 텐서\n",
        "    # 만약 0번째 차원이 배치라면 (batch_size, seq_size, feat_size)\n",
        "    # 아니라면 (seq_size, batch_size, feat_size)\n",
        "  def forward(self, x_in, initial_hidden=None):\n",
        "\n",
        "    if self.batch_first:\n",
        "      batch_size, seq_size, feat_size = x_in.size()\n",
        "      x_in = x_in.permute(1,0,2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}