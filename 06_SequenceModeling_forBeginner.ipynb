{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_SequenceModeling_forBeginner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbQil6FS6aO1Wg0zfGprTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/NLP-withPyTorch/blob/main/06_SequenceModeling_forBeginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QPT35c8LXQ3"
      },
      "source": [
        "자연어는 시계열 데이터이다!\n",
        "\n",
        "따라서 자연어 처리를 위해 시퀀스 모델링이 필요!\n",
        "\n",
        "시퀀스 모델링은 **은닉 상태**를 유지한다.\n",
        "\n",
        "은닉 상태는 지금까지의 시퀀스에 대한 정보를 **시퀀스 표현**에 담는다.\n",
        "\n",
        "시퀀스 모델로 시퀀스를 분류하거나, 생성할 수 있당\n",
        "\n",
        "이번에는 시퀀스 분류를 배워보자~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATBrR4CGZnOJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0POMqhLwUslP"
      },
      "source": [
        "## 6.1 순환 신경망 소개\n",
        "\n",
        "\n",
        "- t에서는 타임 스텝 t에서의 입력 벡터와 타임 스텝 t-1에서의 은닉 벡터를 사용한다.\n",
        "- 각각 은닉-은닉 가중치와 입력-은닉 가중치를 사용한다.\n",
        "- 이때 가중치는어느 시간에서나 같은 파라미터를 공유한다.\n",
        "\n",
        "- 시퀀스 모델은 가변 길이 시퀀스를 다룰 수 있어야 한다.\n",
        "  - 책에서는 마스킹을 사용한다.\n",
        "  - 마스킹을 통해 그레디언트나 최종 출력에 포함되어서는 안된다는 신호를 보낼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5aOS2WYBa-"
      },
      "source": [
        "### 6.1.1 엘만 RNN 구현하기\n",
        "\n",
        "파이토치 RNN 클래스가 엘만 RNN의 구현이다.\n",
        "\n",
        "하지만 여기서는 RNNCell을 사용해 RNN을 만든다!\n",
        "\n",
        "**RNNCell**\n",
        "- 입력-은닉 가중치와 은닉-은닉 가중치\n",
        "- RNNCell() 호출마다 입력 벡터 행렬과 은닉 벡터 행렬을 받는다.\n",
        "- 그리고 은닉 벡터를 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_CDJpW7IHfS"
      },
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "\n",
        "  ## input_size (int) == 입력 벡터 크기\n",
        "  ## hidden_size (int) == 은닉 벡터 크기\n",
        "  ## batch_first (boolean) == 0번째 차원이 배치인가?\n",
        "  def __init__(self, input_size, hidden_size, batch_first=False):\n",
        "    super(ElmanRNN, self).__init__()\n",
        "\n",
        "    ## RNNCell 사용\n",
        "    self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "    self.batch_first = batch_first\n",
        "    self.hidden_size = hidden_size\n",
        "  \n",
        "  def _initialize_hidden(self, batch_size):\n",
        "    return torch.zeros(batch_size, self.hidden_size)\n",
        "  \n",
        "\n",
        "  # ElmanRNN의 정방향 계산\n",
        "  ## x_int (tensor) == 입력 데이터 텐서\n",
        "    # 만약 0번째 차원이 배치라면 (batch_size, seq_size, feat_size)\n",
        "    # 아니라면 (seq_size, batch_size, feat_size)\n",
        "  def forward(self, x_in, initial_hidden=None):\n",
        "\n",
        "    if self.batch_first:\n",
        "      batch_size, seq_size, feat_size = x_in.size()\n",
        "      x_in = x_in.permute(1,0,2)\n",
        "    else:\n",
        "      seq_size, batch_size, feat_size = x_in.size()\n",
        "    \n",
        "    hiddens = []\n",
        "\n",
        "\n",
        "    ## 초기 은닉 상태를 지정하지 않으면 모두 0\n",
        "    if initial_hidden is None:\n",
        "      initial_hidden = self._initialize_hidden(batch_size)\n",
        "      initial_hidden = initial_hidden.to(x_in.device)\n",
        "    \n",
        "    hidden_t = initial_hidden\n",
        "\n",
        "    ## 입력 벡터의 길이만큼 반복하면서 새로운 은닉 상태를 계산해서 쌓아둠\n",
        "    for t in range(seq_size):\n",
        "      hidden_t = self.rnn_cell(x_in[t], hidden_t)\n",
        "      hiddens = torch.stack(hiddens)\n",
        "    \n",
        "    hiddens = torch.stack(hiddens)\n",
        "\n",
        "    if self.batch_first:\n",
        "      hiddens = hiddens.permute(1,0,2)\n",
        "    \n",
        "    ## 3차원 : 각 데이터 포인트/타임 스텝에 대한 은닉 상태 벡터\n",
        "    # 1. 각 타임 스텝을 정해진 범주로 분류\n",
        "    # 2. 최종 벡터를 사용해 전체 시퀀스를 분류\n",
        "    return hiddens"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ug2h2OsCiJ3",
        "outputId": "ad617829-4e75-4345-e63b-690f36d5fc36"
      },
      "source": [
        "x=torch.Tensor([[1,2,3],[1,2,3]])\n",
        "\n",
        "a,b=x.size()\n",
        "print(a,b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4sbB-uGFHte"
      },
      "source": [
        "https://davian-lab-junwoo.tistory.com/17\n",
        "\n",
        "permute와 view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJf7dpHAGzMD"
      },
      "source": [
        "## 6.2 문자 RNN으로 성씨 국적 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rm7HVxYHuex"
      },
      "source": [
        "## 6.3 요약\n",
        "\n",
        "시퀀스 모델링의 목표는 시퀀스에 대한 표현을 학습하는 것이에용.."
      ]
    }
  ]
}