{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_SequenceModeling_forAdvanced.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVpLcwgAHwW/xYQQPA0WA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/NLP-withPyTorch/blob/main/08_SequenceModeling_forAdvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pglSYxPTHJhr"
      },
      "source": [
        "**Sequence to Sequence**\n",
        "\n",
        "S2S 모델은 시퀀스를 입력받아 다른 시퀀스를 출력으로 만든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euz6zjsvHQtt"
      },
      "source": [
        "## 8.1 시퀀스-투-시퀀스 모델, 인코더-디코더 모델, 조건부 생성\n",
        "\n",
        "S2S는 **인코더-디코더 모델**의 일종이다.\n",
        "\n",
        "**인코더** : 입력을 받아 중요한 특징을 감지해 벡터 하나를 출력\n",
        "\n",
        "**디코더** : 인코딩된 입력을 받아 원하는 출력을 생성\n",
        "\n",
        "<br>\n",
        "\n",
        "인코더-디코더 모델은 **조건부 생성 모델**의 일종이다.\n",
        "\n",
        "조건부 생성 모델 : 입력 표현 대신 조건 문맥을 사용해 출력을 만든다.\n",
        "\n",
        "<br>\n",
        "\n",
        "![이미지](https://classic.d2l.ai/_images/seq2seq1.svg)\n",
        "\n",
        "<br>\n",
        "\n",
        "**최신 S2S 모델**\n",
        "1. 양방향 순환 모델 (bidirectional recurrent model)\n",
        "2. 어텐션 메커니즘 (attention mechanism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glGhf0IePmPT"
      },
      "source": [
        "## 8.2 양방향 순환 모델\n",
        "\n",
        "시퀀스를 모델링할 때 지난 단어와 앞으로 나타날 단어를 관찰하면 좋다!\n",
        "\n",
        "<br>\n",
        "**정방향과 역방향 표현을 합침**\n",
        "\n",
        "![](https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz42et8lRmHh"
      },
      "source": [
        "## 8.3 어텐션\n",
        "\n",
        "S2S 모델은 전체 입력 문장을 하나의 벡터에 밀어 넣는다는 문제가 있다.\n",
        "\n",
        "이렇게 최종 은닉 상태만 사용하기 때문에 긴 문장에서 사용하기 어려움!\n",
        "\n",
        "그리고 문장이 길면 그레디언트가 소실됨 ㅠ\n",
        "\n",
        "\n",
        "**그럼 어케?**\n",
        "\n",
        "사람이 번역할 때 문장 전체의 의미를 보기보다는 *breakfast* -> *아침* 이렇게 번역을 함\n",
        "\n",
        "출력을 생성할 때 관련된 입력 부분에 초점을 맞춤\n",
        "\n",
        "이게 바로 **어텐션**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1MrbFNuWA3C"
      },
      "source": [
        "### 8.3.1 심층 신경망의 어텐션\n",
        "\n",
        "어텐션에선는 인코더의 최종 은닉 상태뿐만 아니라 중간 타임 스텝의 은닉 상태도 고려\n",
        "\n",
        "**value, key** = 인코더의 은닉상태\n",
        "\n",
        "**query** = 인코더와 디코더의 은닉 상태\n",
        "\n",
        "    이때 타입 스텝 t=0에서의 쿼리 벡터는 고정된 하이퍼파라미터\n",
        "\n",
        "**attention vector, attention weight** = 주의를 기울이려는 값의 개수와 차원이 같은 백터\n",
        "\n",
        "**context vector, glimpse** = 어텐션 가중치와 인코더 상태를 연결해서 생성\n",
        "\n",
        "이때 전체 문장의 인코딩 대신 문맥 벡터가 디코더의 입력이 됨\n",
        "\n",
        "**compatibilty function** = 다음 타임 스텝 어텐션 벡터 업데이트해주는 함수로, 어텐션 메커니즘마다 달라진다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 어텐션 구현 방법\n",
        "\n",
        "1. 콘텐츠 인식 어텐션\n",
        "2. 위치 인식 어텐션 (쿼리 벡터와 키만 사용)\n",
        "1. 소프트 어텐션 (어텐션 가중치가 0과 1 사이의 실수일때)\n",
        "2. 하드 어텐션 (어텐션이 0 아니면 1일때)\n",
        "1. 지도 어텐션\n",
        "2. 멀티헤드 어텐션\n",
        "3, 셀프 어텐션 (입력의 어떤 영역이 다른 영역에 영향을 미치는지 학습)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-YGFmvim7uz"
      },
      "source": [
        "## 8.4 시퀀스 생성 모델 평가\n",
        "\n",
        "프랑스어 문장 하나에 다양한 영어 번역문이 나올 수 있다\n",
        "\n",
        "그럼 모델 평가는 어케하지..?\n",
        "\n",
        "**참조 출력 (Reference Output)**\n",
        "\n",
        "여러 모델을 비교할 때 모델의 출력이 얼마나 참조 출력에 가까운지를 점수로 매긴다.\n",
        "\n",
        "1. 사람 평가\n",
        "\n",
        "    한 명 이상의 사람이 모델 출력에 좋고 나쁨을 평가\n",
        "\n",
        "    중요하지만 평가 속도가 느리고 비용이 많이 들며 구하기 어려움\n",
        "\n",
        "    또한 사람들 간의 평가가 다를 수도 있어 평가자 간의 일치율(HTER)과 사용해야함\n",
        "\n",
        "2. 자동 평가\n",
        "\n",
        "    n-그램 중복 기반 지표 (참조와 출력이 얼마나 가까운지 계산)\n",
        "\n",
        "    perplexity (출력 시퀀스의 확률)\n",
        "\n",
        "    (이때 혼란도는 지수 함수를 포함해 값이 과장되었고 혼란도 변화는 모델 오차율에 영향을 미치지 않음)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x492JpQq4UA"
      },
      "source": [
        "## 8.5 예제:신경망 기계 번역\n",
        "\n",
        "[코드 보러가기](https://github.com/junieberry/NLP-withPyTorch/tree/main/08_NMT_MachineTranslation)"
      ]
    }
  ]
}