{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_BasicNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3kQBd6rVrUhPZyt7LTecp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/NLP-withPyTorch/blob/main/02_BasicNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZSaSwVsAO2U"
      },
      "source": [
        "## 2.1 말뭉치, 토큰, 타입\n",
        "\n",
        "**말뭉치(corpus)**는 원시 텍스트나 연관된 메타데이터 포함\n",
        "\n",
        "일반적으로 **토큰**으로 묶었을 때 유용함\n",
        "\n",
        "이러한 과정을 **토큰화**라고 함\n",
        "\n",
        "메타데이터가 붙은 텍스트를 **샘플**, 혹은 데이터 포인트라고 일컬음\n",
        "\n",
        "샘플의 모등은 **데이터셋**이라고 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ocq_I6BYms"
      },
      "source": [
        "텍스트 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6nfkVtv_scy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49388ab-8581-4a05-caeb-44f22c89309e"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "text = \"Mary, don't slap the green witch\"\n",
        "tokenized_text = [str(token) for token in nlp(text.lower())]\n",
        "\n",
        "print(tokenized_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mary', ',', 'do', \"n't\", 'slap', 'the', 'green', 'witch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACAoD-njZF2V"
      },
      "source": [
        "## 2.2 유니그램, 바이그램, 트라이그램, n-그램\n",
        "\n",
        "**n-그램(n-gram)**은 텍스트에 있는 고정 길이 n의 연속된 토큰 시퀀스\n",
        "\n",
        "때론 부분 단어의 정보가 유용할 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCkLslPCajqC",
        "outputId": "25b66473-cc48-4005-c473-5cdd134b3d45"
      },
      "source": [
        "def n_grams(text, n):\n",
        "  return [text[i:i+n] for i in range(len(text)-n+1)]\n",
        "\n",
        "print(n_grams(tokenized_text, 3))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['mary', ',', 'do'], [',', 'do', \"n't\"], ['do', \"n't\", 'slap'], [\"n't\", 'slap', 'the'], ['slap', 'the', 'green'], ['the', 'green', 'witch']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX_ISMo_bUGK"
      },
      "source": [
        "## 2.3 표제어와 어간\n",
        "\n",
        "**표제어(lemma)** : 단어의 기본형\n",
        "\n",
        "fly는 flew, flies 등의 표제어이다.\n",
        "\n",
        "토큰을 표제어로 바꾸어 벡터 표현의 차원을 줄이기도 한다.\n",
        "\n",
        "아래 예제에서 spaCy는 사전에 정의된 WordNet을 사용해 표제어를 추출한다.\n",
        "\n",
        "이러한 표제어 추출 방식 대신 **어간 추출(stemming)** 방식도 있다.\n",
        "\n",
        "어간 추출 방식에서는 수동으로 만든 규칙을 통해 단어의 끝을 잘라 어간 형태로 축소한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9RjW9FceR69",
        "outputId": "ac98f022-a77d-4110-efc2-929b32f66078"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp(u\"he was running late\")\n",
        "for token in doc:\n",
        "  print('{} --> {}'.format(token, token.lemma_))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he --> -PRON-\n",
            "was --> be\n",
            "running --> run\n",
            "late --> late\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP1pmKKmfecG"
      },
      "source": [
        "## 2.4 문장과 문서 분류하기\n",
        "\n",
        "1장의 TF나 TF-IDF가 긴 텍스트 뭉치 분류에 용이하다.\n",
        "\n",
        "레이블된 데이터셋이 적을 때는 준지도 학습이 유용하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0qc2-dUg0hN"
      },
      "source": [
        "## 2.5 단어 분류하기: 품사 태깅\n",
        "\n",
        "**품사 : part-of-speech(POS)**\n",
        "\n",
        "단어 분류 작업의 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpNoaDp7g_t6",
        "outputId": "872e43ba-8a0e-4d84-ea4c-bcb7926748bb"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp(u\"Mary slapped the green witch.\")\n",
        "for token in doc:\n",
        "  print('{} -- {}'.format(token, token.pos_))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary -- PROPN\n",
            "slapped -- VERB\n",
            "the -- DET\n",
            "green -- ADJ\n",
            "witch -- NOUN\n",
            ". -- PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt8y3gycg_c3"
      },
      "source": [
        "## 2.6 청크 나누기와 개체명 인식\n",
        "\n",
        "때로는 텍스트 구에 레이블을 할당해야 한다.\n",
        "\n",
        "```\n",
        "[NP Mary] [VP slapped] [the green witch].\n",
        "```\n",
        "\n",
        "NP = 명사구\n",
        "\n",
        "VP = 동사구\n",
        "\n",
        "\n",
        "이와 같은 **chunking** 혹은 **shallow parsing**을 통해 고차원의 단위를 유도할 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTqrw1Ssjlot"
      },
      "source": [
        "## 2.7 문장 구조\n",
        "\n",
        "구 단위를 식별하는 부분 구문 분석과 다르게 **구문 분석(parsing)**은 구 사이의 관계를 파악한다.\n",
        "\n",
        "- 구성 구문 분석\n",
        "- 의존 구문 분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMHgLiYPj4gB"
      },
      "source": [
        "## 2.8 단어 의미와 의미론\n",
        "\n",
        "단어에는 의미가 하나 이상 있다.\n",
        "\n",
        "이때의 의미를 **sense**라고 한다."
      ]
    }
  ]
}